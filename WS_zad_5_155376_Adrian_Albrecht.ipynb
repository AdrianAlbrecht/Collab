{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importowanie potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytywanie obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'z1.png'\n",
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicjalizacja kaskady Haara dla detekcji twarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konwersja obrazu na odcienie szarości (wymagane dla detektora twarzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detekcja twarzy\n",
    "## (w tym przykładzie jest tylko jedna, natomiast jeżeli byłoby więcej to byłaby to lista współrzędnych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rysujemy czerwony prostokąt wokół znalezionej twarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zapisujemy wynikowy obraz jako 'z1_reco_png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'z1_reco.png'\n",
    "cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teraz robimy to samo, ale dla zdjecia z większą ilością osób. Jest to zdjęcie z przeprowadzanego szkolenia dla dzieci ze Scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'z2.png'\n",
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicjalizacja kaskady Haara dla detekcji twarzy, oczu i uśmiechu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "nose_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_mcs_nose.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detekcja twarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5, minSize=(50, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteracja po każdej znalezionej twarzy w celu znalezienia uśmiechów itd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     cv2\u001b[39m.\u001b[39mrectangle(roi_color, (sx, sy), (sx\u001b[39m+\u001b[39msw, sy\u001b[39m+\u001b[39msh), (\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Detekcja nosa \u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m noses \u001b[39m=\u001b[39m nose_cascade\u001b[39m.\u001b[39;49mdetectMultiScale(roi_gray, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m4.9\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, flags\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mCASCADE_SCALE_IMAGE)\n\u001b[0;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m (nx, ny, nw, nh) \u001b[39min\u001b[39;00m noses:\n\u001b[0;32m     21\u001b[0m     cv2\u001b[39m.\u001b[39mrectangle(roi_color, (nx, ny), (nx\u001b[39m+\u001b[39mnw, ny\u001b[39m+\u001b[39mnh), (\u001b[39m255\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "    # Region zainteresowania (ROI) dla detekcji oczu i uśmiechu\n",
    "    roi_gray = gray_image[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Detekcja oczu (na zielono)\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "\n",
    "    # Detekcja uśmiechu (na niebiesko)\n",
    "    smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25))\n",
    "    for (sx, sy, sw, sh) in smiles:\n",
    "        cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (255,0,0), 2)\n",
    "\n",
    "    # Detekcja nosa \n",
    "    noses = nose_cascade.detectMultiScale(roi_gray, scaleFactor=4.9, minNeighbors=4, flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (nx, ny, nw, nh) in noses:\n",
    "        cv2.rectangle(roi_color, (nx, ny), (nx+nw, ny+nh), (255, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niestety, ale nosy jak widać nie chcą współpracować, spróbujmy bez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "    # Region zainteresowania (ROI) dla detekcji oczu i uśmiechu\n",
    "    roi_gray = gray_image[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Detekcja oczu (na zielono)\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "\n",
    "    # Detekcja uśmiechu (na niebiesko)\n",
    "    smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25))\n",
    "    for (sx, sy, sw, sh) in smiles:\n",
    "        cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (255,0,0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zapisujemy obraz jako 'z2_reco.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'z2_reco.png'\n",
    "cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nie wykrył wszystkich twarzy, uśmiechców wcale, a oczy czasami wykrywał tylko jedno z pary. Zmodyfikujmy parametry dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'z2.png'\n",
    "image = cv2.imread(image_path)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=4, minSize=(40, 40))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "    roi_gray = gray_image[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Detekcja oczu (na zielono) ze zmodyfikowaną wartością\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.05, minNeighbors=2, minSize=(10, 10))\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "\n",
    "    # Detekcja uśmiechu (na niebiesko) ze zmodyfikowaną wartością\n",
    "    smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.05, minNeighbors=10, minSize=(10, 19))\n",
    "    for (sx, sy, sw, sh) in smiles:\n",
    "        cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (255,0,0), 2)\n",
    "        \n",
    "output_path = 'z2_reco_best.png'\n",
    "cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jest nieco lepiej, ale lepszych efektów nie dało sie uzyskać. Część twarzy nie jest wykryta, niektóre osoby zyskały 'dodatkowe oczy' a część z nich została cyklopem. Część z osób nie ma uśmiechów, a u części nie wykryto tego uśmiechu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wypiszemy wykrytą ilość osób na zdjeciu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba osób na zdjęciu: 23\n"
     ]
    }
   ],
   "source": [
    "print(f'Liczba osób na zdjęciu: {len(faces)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zróbmy to tez HOG'iem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 0.5\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "image_path = 'z2.png'\n",
    "image = cv2.imread(image_path)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "people_rects = hog.detectMultiScale(gray_image, winStride=(4,4), padding=(30,30), scale=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narysujmy prostokąty rozpoznajace osobę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in people_rects[0]:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... i zapiszmy wynik jako 'z2_count.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'z2_count.png'\n",
    "cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dla tego przykładu działa to miernie, może inne zdjęcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba osób na zdjęciu: 2\n"
     ]
    }
   ],
   "source": [
    "image_path = 'z2_2.png'\n",
    "image = cv2.imread(image_path)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "people_rects = hog.detectMultiScale(gray_image, winStride=(8,8), padding=(30,30), scale=1.1)\n",
    "for (x, y, w, h) in people_rects[0]:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 5)\n",
    "output_path = 'z2_2_count.png'\n",
    "cv2.imwrite(output_path, image)\n",
    "print(f'Liczba osób na zdjęciu: {len(people_rects[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lepiej, przejdźmy dalej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicjalizacja kamery laptopa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # Jeśli jest więcej niż jedna kamera, zamienić 0 na odpowiednią wartość"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawdzamy, czy kamera jest dostępna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cap.isOpened():\n",
    "    print(\"Błąd: Nie można otworzyć kamery.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Działa, zatem... \n",
    "# Tworzymy okno do wyświetlania obrazu z kamery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('Detekcja Twarzy', cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ustawiamy szerokość i wysokość okna wideo na profesjonalne 640x480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzymy obiekt VideoWriter, do którego będziemy zapisywać nasz filmik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('z3_output.mp4', fourcc, 20.0, (640, 480))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importujemy moduł time żeby zmierzyć czas trwania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pętla główna do odczytu i wyświetlania klatek z kamery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "while True:\n",
    "    # Odczyt klatki z kamery\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Błąd: Nie można odczytać klatki.\")\n",
    "        break\n",
    "\n",
    "    # Konwersja klatki na odcienie szarości (wymagane dla detektora twarzy)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detekcja twarzy\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Rysujemy prostokąt wokół każdej znalezionej twarzy\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Zapisujemy klatkę do pliku wideo\n",
    "    out.write(frame)\n",
    "\n",
    "    # Przerywamy pętlę, jeśli minęło 35 sekund\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time > 35:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zwalniamy zasoby, zamykamy okno i zapisujemy plik wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jak widać algorytm przy obrotach twarzy i szybszych ruchach momentami traci wykrywanie. Może to być to też spowodowane słabą jakością kamerki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolejne zadanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicjalizacja wideo\n",
    "video_path = 'z4.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Sprawdźmy, czy plik wideo jest otwarty\n",
    "if not cap.isOpened():\n",
    "    print(\"Błąd: Nie można otworzyć pliku wideo.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicjalizacja kaskady Haara dla detekcji pieszych i twarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrian_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzymy obiekt VideoWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('z4_output.mp4', fourcc, 20.0, (1920, 1080))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pętla główna do odczytu i przetwarzania klatek z wideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brak nowych klatek do przetworzenia. Koniec wideo.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Odczyt klatki z wideo\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Sprawdzamy, czy udało się odczytać klatkę\n",
    "    if not ret:\n",
    "        print(\"Brak nowych klatek do przetworzenia. Koniec wideo.\")\n",
    "        break\n",
    "\n",
    "    # Konwersja klatki na odcienie szarości (wymagane dla detekcji pieszych i twarzy)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detekcja pieszych\n",
    "    pedestrians = pedestrian_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=3, minSize=(20, 20))\n",
    "\n",
    "    # Rysujemy prostokąt wokół każdego znalezionego pieszego\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Region zainteresowania (ROI) dla detekcji twarzy\n",
    "        roi_gray = gray_frame[y:y+h, x:x+w]\n",
    "        faces = face_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=4, minSize=(10, 10))\n",
    "        \n",
    "        # Rysujemy prostokąt wokół każdej znalezionej twarzy\n",
    "        for (fx, fy, fw, fh) in faces:\n",
    "            cv2.rectangle(frame, (x + fx, y + fy), (x + fx + fw, y + fy + fh), (255, 0, 0), 2)\n",
    "\n",
    "    # Zapisujemy klatkę do pliku wideo\n",
    "    out.write(frame)\n",
    "\n",
    "# Zwolniamy zasoby i zapisujemy plik wideo\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ostatni algorytm wykunuje się bardzo długo, bo aż ok 7 minut, czyli ponad 10 razy dłużej, niż trwa materiał, natopmiast wyniki są różne, jeżeli to kamera się porusza, to wykrywanie jest mierne natomiast gdy kamera jest statyczna to wykrywanie działa aż nadmiarowo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3f0d207b648d1175a3b2bbb912118d4848417bdf0b1a5227ab0916c63215186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
